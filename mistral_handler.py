# mistral_handler.py - v1.0
"""
Handler pour API Mistral AI
Compatible avec architecture modulaire email_monitor v3.1.0
"""

import os
import requests
from typing import Optional


def handle_mistral_maritime_assistant(user_message: str) -> str:
    """
    Assistant maritime sp√©cialis√© avec Mistral
    Optimis√© pour questions nautiques, m√©t√©o, navigation
    
    Args:
        user_message: Question de l'utilisateur
        
    Returns:
        R√©ponse de Mistral (texte brut)
    """
    api_key = os.getenv('MISTRAL_API_KEY')
    
    if not api_key:
        return "‚ùå MISTRAL_API_KEY non configur√©e"
    
    try:
        print(f"\n{'='*70}")
        print("üß† MISTRAL MARITIME ASSISTANT")
        print(f"{'='*70}")
        print(f"Question: {user_message[:100]}...")
        
        url = "https://api.mistral.ai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        system_prompt = """Tu es un assistant maritime expert pour navigateurs en mer.

Contexte:
- Utilisateur en mer sur voilier
- Communication satellite limit√©e et co√ªteuse
- Besoin r√©ponses ULTRA-CONCISES

Expertise:
- M√©t√©orologie marine
- Navigation hauturi√®re
- S√©curit√© maritime
- M√©canique marine
- Protocoles d'urgence
- Interpr√©tation fichiers GRIB

R√àGLES STRICTES:
- MAX 160 caract√®res par r√©ponse
- Info essentielle UNIQUEMENT
- Vocabulaire maritime pr√©cis
- Conseils pratiques directs
- Pas de fioriture

Questions hors maritime: d√©cliner poliment."""
        
        data = {
            "model": "mistral-large-latest",
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_message
                }
            ],
            "max_tokens": 512,  # Limit√© pour r√©ponses concises
            "temperature": 0.7
        }
        
        print("üì§ Envoi requ√™te API Mistral...")
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip()
            
            # Infos usage
            usage = result.get('usage', {})
            input_tokens = usage.get('prompt_tokens', 0)
            output_tokens = usage.get('completion_tokens', 0)
            
            # Calcul co√ªt (Mistral Large: $2/$6 per M tokens)
            input_cost = (input_tokens / 1_000_000) * 2.0
            output_cost = (output_tokens / 1_000_000) * 6.0
            total_cost = input_cost + output_cost
            
            print(f"‚úÖ R√©ponse Mistral re√ßue: {len(answer)} chars")
            print(f"üìä Tokens: {input_tokens} in + {output_tokens} out")
            print(f"üí∞ Co√ªt: ${total_cost:.6f}")
            print(f"{'='*70}\n")
            
            return answer
            
        else:
            error_msg = f"‚ùå Erreur API Mistral: {response.status_code}"
            print(error_msg)
            print(f"R√©ponse: {response.text[:200]}")
            return f"Erreur Mistral: {response.status_code}"
            
    except Exception as e:
        error_msg = f"‚ùå Erreur Mistral: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return f"Erreur: {str(e)[:100]}"


def handle_mistral_request(user_message: str, max_tokens: int = 1024) -> str:
    """
    Requ√™te Mistral g√©n√©rique (non sp√©cialis√©e maritime)
    
    Args:
        user_message: Message utilisateur
        max_tokens: Limite de tokens (d√©faut: 1024)
        
    Returns:
        R√©ponse de Mistral
    """
    api_key = os.getenv('MISTRAL_API_KEY')
    
    if not api_key:
        return "‚ùå MISTRAL_API_KEY non configur√©e"
    
    try:
        print(f"\n{'='*70}")
        print("üß† MISTRAL REQUEST")
        print(f"{'='*70}")
        print(f"Message: {user_message[:100]}...")
        print(f"Max tokens: {max_tokens}")
        
        url = "https://api.mistral.ai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "mistral-large-latest",
            "messages": [
                {
                    "role": "user",
                    "content": user_message
                }
            ],
            "max_tokens": max_tokens,
            "temperature": 0.7
        }
        
        print("üì§ Envoi requ√™te API Mistral...")
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip()
            
            usage = result.get('usage', {})
            input_tokens = usage.get('prompt_tokens', 0)
            output_tokens = usage.get('completion_tokens', 0)
            
            input_cost = (input_tokens / 1_000_000) * 2.0
            output_cost = (output_tokens / 1_000_000) * 6.0
            total_cost = input_cost + output_cost
            
            print(f"‚úÖ R√©ponse: {len(answer)} chars")
            print(f"üìä Tokens: {input_tokens}/{output_tokens}")
            print(f"üí∞ Co√ªt: ${total_cost:.6f}")
            print(f"{'='*70}\n")
            
            return answer
            
        else:
            error_msg = f"‚ùå Erreur API: {response.status_code}"
            print(error_msg)
            return f"Erreur Mistral: {response.status_code}"
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return f"Erreur: {str(e)[:100]}"


def handle_mistral_weather_expert(user_message: str) -> str:
    """
    Expert m√©t√©o marine sp√©cialis√© avec Mistral
    
    Args:
        user_message: Question m√©t√©o
        
    Returns:
        Analyse m√©t√©o de Mistral
    """
    api_key = os.getenv('MISTRAL_API_KEY')
    
    if not api_key:
        return "‚ùå MISTRAL_API_KEY non configur√©e"
    
    try:
        print(f"\n{'='*70}")
        print("üåä MISTRAL WEATHER EXPERT")
        print(f"{'='*70}")
        print(f"Question: {user_message[:100]}...")
        
        url = "https://api.mistral.ai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        system_prompt = """Expert m√©t√©orologie marine pour navigation hauturi√®re.

Sp√©cialit√©s:
- Interpr√©tation GRIB (vent, vagues, pression)
- Pr√©visions route oc√©anique
- Fen√™tres m√©t√©o favorables
- Syst√®mes d√©pressionnaires
- Strat√©gie routage

Format r√©ponse:
- Synth√®se conditions (2-3 lignes max)
- Recommandation cap/timing
- Alertes si danger
- CONCIS et ACTIONNABLE

Unit√©s: n≈ìuds, mbar, degr√©s vrais."""
        
        data = {
            "model": "mistral-large-latest",
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_message
                }
            ],
            "max_tokens": 512,
            "temperature": 0.7
        }
        
        print("üì§ Envoi requ√™te API Mistral Weather...")
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip()
            
            usage = result.get('usage', {})
            input_tokens = usage.get('prompt_tokens', 0)
            output_tokens = usage.get('completion_tokens', 0)
            
            input_cost = (input_tokens / 1_000_000) * 2.0
            output_cost = (output_tokens / 1_000_000) * 6.0
            total_cost = input_cost + output_cost
            
            print(f"‚úÖ R√©ponse Weather: {len(answer)} chars")
            print(f"üìä Tokens: {input_tokens}/{output_tokens}")
            print(f"üí∞ Co√ªt: ${total_cost:.6f}")
            print(f"{'='*70}\n")
            
            return answer
            
        else:
            error_msg = f"‚ùå Erreur API: {response.status_code}"
            print(error_msg)
            return f"Erreur Mistral Weather: {response.status_code}"
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return f"Erreur: {str(e)[:100]}"


def split_long_response(response: str, max_length: int = 160) -> list:
    """
    D√©coupe une r√©ponse longue en messages inReach (max 160 chars)
    
    Args:
        response: Texte √† d√©couper
        max_length: Longueur max par message
        
    Returns:
        Liste de messages d√©coup√©s
    """
    if len(response) <= max_length:
        return [response]
    
    messages = []
    words = response.split()
    current_msg = ""
    
    for word in words:
        test_msg = current_msg + " " + word if current_msg else word
        
        if len(test_msg) <= max_length:
            current_msg = test_msg
        else:
            if current_msg:
                messages.append(current_msg)
            current_msg = word
    
    if current_msg:
        messages.append(current_msg)
    
    return messages


# Test du module
if __name__ == "__main__":
    print("="*70)
    print("TEST MISTRAL HANDLER v1.0")
    print("="*70)
    
    # Test 1: Question maritime
    print("\nüìù Test 1: Question maritime")
    print("-"*70)
    response = handle_mistral_maritime_assistant(
        "Comment r√©duire voilure si vent 40 n≈ìuds?"
    )
    print(f"R√©ponse: {response}\n")
    
    # Test 2: Expert m√©t√©o
    print("\nüìù Test 2: Expert m√©t√©o")
    print("-"*70)
    response = handle_mistral_weather_expert(
        "GRIB montre 25kt NO demain. Bon pour cap 270¬∞?"
    )
    print(f"R√©ponse: {response}\n")
    
    # Test 3: D√©coupage message long
    print("\nüìù Test 3: D√©coupage message")
    print("-"*70)
    long_response = "Pour naviguer en s√©curit√© par forte mer, il est recommand√© de r√©duire la voilure progressivement, de maintenir un cap stable, de s√©curiser tout l'√©quipement de pont, et de mettre en place des tours de quart pour surveiller les conditions m√©t√©orologiques."
    
    segments = split_long_response(long_response, max_length=160)
    print(f"Message original: {len(long_response)} chars")
    print(f"D√©coup√© en: {len(segments)} segments")
    for i, segment in enumerate(segments, 1):
        print(f"  Segment {i}/{len(segments)} ({len(segment)} chars): {segment}")
    
    print("\n" + "="*70)
    print("TESTS TERMIN√âS")
    print("="*70)
